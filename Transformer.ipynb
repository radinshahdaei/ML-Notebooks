{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0277472866944fbae6a4f8c3d204c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d47670e4aa24d92b9a26dbfbb46cba5",
              "IPY_MODEL_2a1d993cd4314f85b68341220ee8b585",
              "IPY_MODEL_6834db95fa3b45c18df5b4b8dca50cbc"
            ],
            "layout": "IPY_MODEL_e80d405bcce5452b824bbfbd26400ca5"
          }
        },
        "4d47670e4aa24d92b9a26dbfbb46cba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_113bcee4a2a84c7d864cf6e79d844ac5",
            "placeholder": "​",
            "style": "IPY_MODEL_b9fd3a1495414eb8afa2f76b5ff6078b",
            "value": "README.md: 100%"
          }
        },
        "2a1d993cd4314f85b68341220ee8b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9236224bf234c85a6e370779240afb5",
            "max": 28064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c4275a4a2be4e26a71ae9bbce973b45",
            "value": 28064
          }
        },
        "6834db95fa3b45c18df5b4b8dca50cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f941fe0e14ee4845a175d293c6d826d8",
            "placeholder": "​",
            "style": "IPY_MODEL_49e8ae1a041f46d6800106a2d5e6f9c9",
            "value": " 28.1k/28.1k [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "e80d405bcce5452b824bbfbd26400ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "113bcee4a2a84c7d864cf6e79d844ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fd3a1495414eb8afa2f76b5ff6078b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9236224bf234c85a6e370779240afb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4275a4a2be4e26a71ae9bbce973b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f941fe0e14ee4845a175d293c6d826d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e8ae1a041f46d6800106a2d5e6f9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f5bd351e9d34e79b514ca4e7cc85c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdcbe3ad4edf405aa561e68c16b05388",
              "IPY_MODEL_c581862600a04811a781880cfb63f2f3",
              "IPY_MODEL_fd3b7fb2719e4a8b8fa4e53da171f60f"
            ],
            "layout": "IPY_MODEL_598342248f5a4916b146388c3de8ddfc"
          }
        },
        "cdcbe3ad4edf405aa561e68c16b05388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2858b9dc5774a22a7db0a96d71e0056",
            "placeholder": "​",
            "style": "IPY_MODEL_f86b36dc5b53425096222cb630539690",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "c581862600a04811a781880cfb63f2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af53704dc6142adaa0b418f9f8fdec3",
            "max": 5726189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d58a4e4677d64f048a47ae28e79cbe76",
            "value": 5726189
          }
        },
        "fd3b7fb2719e4a8b8fa4e53da171f60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749c8864bf584033b0c4fc081d220a12",
            "placeholder": "​",
            "style": "IPY_MODEL_3f96fdc89c5e414f8c5f7f4f0c25908e",
            "value": " 5.73M/5.73M [00:00&lt;00:00, 21.9MB/s]"
          }
        },
        "598342248f5a4916b146388c3de8ddfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2858b9dc5774a22a7db0a96d71e0056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86b36dc5b53425096222cb630539690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af53704dc6142adaa0b418f9f8fdec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58a4e4677d64f048a47ae28e79cbe76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "749c8864bf584033b0c4fc081d220a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f96fdc89c5e414f8c5f7f4f0c25908e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "126087714091462ea671f937a1008971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ea157093fc7424c932db9f8bf4f1054",
              "IPY_MODEL_767026d8aafa4992b610484f568a4d85",
              "IPY_MODEL_cf3c396376f44621a348bac68d2521c4"
            ],
            "layout": "IPY_MODEL_2437e77564d34e5eb39067fc6d403ae6"
          }
        },
        "9ea157093fc7424c932db9f8bf4f1054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1ef2e0cb824a60896150598514df3c",
            "placeholder": "​",
            "style": "IPY_MODEL_9ccb431b0d45443a9ed619800327b096",
            "value": "Generating train split: 100%"
          }
        },
        "767026d8aafa4992b610484f568a4d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaab2016f3d547eba8027f6853fb79d7",
            "max": 32332,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51c51faa4cd94706bd5acc5fd73df56c",
            "value": 32332
          }
        },
        "cf3c396376f44621a348bac68d2521c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e714f39277f4028bfdf00f8805d3725",
            "placeholder": "​",
            "style": "IPY_MODEL_5569955af7c447efae4b5642787a390f",
            "value": " 32332/32332 [00:00&lt;00:00, 76711.98 examples/s]"
          }
        },
        "2437e77564d34e5eb39067fc6d403ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1ef2e0cb824a60896150598514df3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ccb431b0d45443a9ed619800327b096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaab2016f3d547eba8027f6853fb79d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c51faa4cd94706bd5acc5fd73df56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e714f39277f4028bfdf00f8805d3725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5569955af7c447efae4b5642787a390f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceb42ac096754d8fba2312ddf89a253d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f44fd96b2bf147d9bbbe3ba2de367348",
              "IPY_MODEL_0d171d30693d49afa8b2cbb3378cb534",
              "IPY_MODEL_82a6223a285149abbc209fff6421ed26"
            ],
            "layout": "IPY_MODEL_5cfd4e782ebf48719be69afb98e1d86a"
          }
        },
        "f44fd96b2bf147d9bbbe3ba2de367348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b70a1080bc546ae8fb2255272474236",
            "placeholder": "​",
            "style": "IPY_MODEL_6a27a31a184b405089d92d60679c6ed7",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0d171d30693d49afa8b2cbb3378cb534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c1247064e54c96bdfb86183f32e56e",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_877cf1d66e8846e58076d03f4f495fb1",
            "value": 48
          }
        },
        "82a6223a285149abbc209fff6421ed26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f64ae9c6888342a791ab25ea31a3b6ee",
            "placeholder": "​",
            "style": "IPY_MODEL_1262d4a91aee43d89234918a2e8f4522",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.18kB/s]"
          }
        },
        "5cfd4e782ebf48719be69afb98e1d86a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b70a1080bc546ae8fb2255272474236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a27a31a184b405089d92d60679c6ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78c1247064e54c96bdfb86183f32e56e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877cf1d66e8846e58076d03f4f495fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f64ae9c6888342a791ab25ea31a3b6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1262d4a91aee43d89234918a2e8f4522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "953d989b9e214940aa824d865f3fb98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06249cf8dfc349d98cc473e905ce28c3",
              "IPY_MODEL_538522f78251403c879314c6357cabfe",
              "IPY_MODEL_4e1940199bd04361b73b3ea370576513"
            ],
            "layout": "IPY_MODEL_9c981791b30e428180f0f44a3ebfd5fc"
          }
        },
        "06249cf8dfc349d98cc473e905ce28c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a4e2626b844ea7ba6a4d42adef9abb",
            "placeholder": "​",
            "style": "IPY_MODEL_512766aeb9ee443f9907539c75bae562",
            "value": "vocab.txt: 100%"
          }
        },
        "538522f78251403c879314c6357cabfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226dd29a783244d586f01932d1415384",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d712e43ace9b4ec4a5cb419ab30e160e",
            "value": 231508
          }
        },
        "4e1940199bd04361b73b3ea370576513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8ed5b6ec724112b6d740cb65c11600",
            "placeholder": "​",
            "style": "IPY_MODEL_a79b7fc75f3a4c47a78f852954e22d45",
            "value": " 232k/232k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "9c981791b30e428180f0f44a3ebfd5fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a4e2626b844ea7ba6a4d42adef9abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512766aeb9ee443f9907539c75bae562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "226dd29a783244d586f01932d1415384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d712e43ace9b4ec4a5cb419ab30e160e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f8ed5b6ec724112b6d740cb65c11600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79b7fc75f3a4c47a78f852954e22d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98025bfad14049eebdebe18d4f9f80f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1d4bd85dbac474c82588b894f2ea68e",
              "IPY_MODEL_63cb115e204441b9bf4338c5afeb6551",
              "IPY_MODEL_3739b2bf65214b76bd67d20c39667f94"
            ],
            "layout": "IPY_MODEL_55910a9c432d4c50a55d68ddcdfbf7e5"
          }
        },
        "c1d4bd85dbac474c82588b894f2ea68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f205810405a14461b54f06e6ccd761b0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d9c7578ffd24da7a5b3d53f1dd42e1e",
            "value": "tokenizer.json: 100%"
          }
        },
        "63cb115e204441b9bf4338c5afeb6551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_014cf75abb31433ea7e0aabcfe399d5b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56c65795b1b346ce845ee36346709129",
            "value": 466062
          }
        },
        "3739b2bf65214b76bd67d20c39667f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c22b43dd082841588ee09d0ef713c33b",
            "placeholder": "​",
            "style": "IPY_MODEL_d775969c4d39476687e1fc0a51931aab",
            "value": " 466k/466k [00:00&lt;00:00, 725kB/s]"
          }
        },
        "55910a9c432d4c50a55d68ddcdfbf7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f205810405a14461b54f06e6ccd761b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9c7578ffd24da7a5b3d53f1dd42e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "014cf75abb31433ea7e0aabcfe399d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c65795b1b346ce845ee36346709129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c22b43dd082841588ee09d0ef713c33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d775969c4d39476687e1fc0a51931aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdb212e89e8c40d686c44d98924ef2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fae1b191304545c188d903f2137280b2",
              "IPY_MODEL_5bb7024eef44406db60b5ff205b3b460",
              "IPY_MODEL_dd2e4ff3acbb43488cc72ad5c7973b55"
            ],
            "layout": "IPY_MODEL_dd7ddbcd74de41b2aa7f3e28b8552c40"
          }
        },
        "fae1b191304545c188d903f2137280b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ea28e5c77464fe18d348e30e0e6f410",
            "placeholder": "​",
            "style": "IPY_MODEL_e96b05bdcdec4bdfbdcb23b8cb1145aa",
            "value": "config.json: 100%"
          }
        },
        "5bb7024eef44406db60b5ff205b3b460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de84e73b7f74d7e97e16564d7564d6c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d600ca7f1c974aa98d5e8b5da7f5c7ba",
            "value": 570
          }
        },
        "dd2e4ff3acbb43488cc72ad5c7973b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7c1a124f4d419c95c68bdd4fcf8214",
            "placeholder": "​",
            "style": "IPY_MODEL_07394e00ffd944e09e4616cc80f8fd9e",
            "value": " 570/570 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "dd7ddbcd74de41b2aa7f3e28b8552c40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea28e5c77464fe18d348e30e0e6f410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e96b05bdcdec4bdfbdcb23b8cb1145aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de84e73b7f74d7e97e16564d7564d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d600ca7f1c974aa98d5e8b5da7f5c7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f7c1a124f4d419c95c68bdd4fcf8214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07394e00ffd944e09e4616cc80f8fd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<font>\n",
        "<div dir=ltr align=center>\n",
        "<img src=\"https://cdn.freebiesupply.com/logos/large/2x/sharif-logo-png-transparent.png\" width=150 height=150> <br>\n",
        "<font color=0F5298 size=7>\n",
        "    Machine learning <br>\n",
        "<font color=2565AE size=5>\n",
        "    Computer Engineering Department <br>\n",
        "    Fall 2024<br>\n",
        "<font color=3C99D size=5>\n",
        "    Practical Assignment 5 - NLP - Transformer & Bert <br>\n",
        "</div>\n",
        "<div dir=ltr align=center>\n",
        "<font color=0CBCDF size=4>\n",
        "   &#x1F349; Masoud Tahmasbi  &#x1F349;  &#x1F353; Arash Ziyaei &#x1F353;\n",
        "<br>\n",
        "<font color=0CBCDF size=4>\n",
        "   &#x1F335; Amirhossein Akbari  &#x1F335;\n",
        "</div>\n",
        "\n",
        "____"
      ],
      "metadata": {
        "id": "VivaFsd3Q6cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=9999FF size=4>\n",
        "&#x1F388; Full Name : Radin Shahadei\n",
        "<br>\n",
        "<font color=9999FF size=4>\n",
        "&#x1F388; Student Number : 401106096"
      ],
      "metadata": {
        "id": "k15QziPnmC6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=0080FF size=3>\n",
        "This notebook covers two key topics. First, we implement a transformer model from scratch and apply it to a specific task. Second, we fine-tune the BERT model using LoRA for efficient adaptation to a downstream task.\n",
        "</font>\n",
        "<br>\n",
        "\n",
        "**Note:**\n",
        "<br>\n",
        "<font color=66B2FF size=2>In this notebook, you are free to use any function or model from PyTorch to assist with the implementation. However, TensorFlow is not permitted for this exercise. This ensures consistency and alignment with the tools being focused on.</font>\n",
        "<br>\n",
        "<font color=red size=3>**Run All Cells Before Submission**</font>: <font color=FF99CC size=2>Before saving and submitting your notebook, please ensure you run all cells from start to finish. This practice guarantees that your notebook is self-consistent and can be evaluated correctly by others.</font>"
      ],
      "metadata": {
        "id": "IOfpEN2xmbN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Transformer\n",
        "\n",
        "The transformer architecture consists of two main components: an encoder and a decoder. Each of these components is made up of multiple layers that include self-attention mechanisms and feedforward neural networks. The self-attention mechanism is central to the transformer, as it enables the model to assess the importance of different words in a sentence by considering their relationships with one another.\n",
        "\n",
        "\n",
        "In this assignment, you should design a transformer model from scratch. You are required to implement the Encoder and Decoder components of a Transformer model."
      ],
      "metadata": {
        "id": "SpvvM0995ieR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "kwiuyxYvc9p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Beiuki8KdIbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Math\n",
        "import math\n",
        "import os\n",
        "import torchmetrics\n",
        "# HuggingFace libraries\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "# Pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "# typing\n",
        "from typing import Any\n",
        "\n",
        "# Library for progress bars in loops\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Importing library of warnings\n",
        "import warnings"
      ],
      "metadata": {
        "id": "dzIob6-Gq7Lw",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:58:45.472195Z",
          "iopub.execute_input": "2025-01-05T15:58:45.472392Z",
          "iopub.status.idle": "2025-01-05T15:58:59.504628Z",
          "shell.execute_reply.started": "2025-01-05T15:58:45.472373Z",
          "shell.execute_reply": "2025-01-05T15:58:59.503722Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Input Embeddings\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we observe the Transformer architecture image above, we can see that the Embeddings represent the first step of both blocks.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>InputEmbedding</code> class below is responsible for converting the input text into numerical vectors of <code>d_model</code> dimensions. To prevent that our input embeddings become extremely small, we normalize them by multiplying them by the $\\sqrt{d_{model}}$.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the image below, we can see how the embeddings are created. First, we have a sentence that gets split into tokens—we will explore what tokens are later on—. Then, the token IDs—identification numbers—are transformed into the embeddings, which are high-dimensional vectors.</p>"
      ],
      "metadata": {
        "id": "-71SfIAJprox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "J-pyrJlu4Nl7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:05.547153Z",
          "iopub.execute_input": "2025-01-05T15:59:05.547440Z",
          "iopub.status.idle": "2025-01-05T15:59:05.552536Z",
          "shell.execute_reply.started": "2025-01-05T15:59:05.547419Z",
          "shell.execute_reply": "2025-01-05T15:59:05.551587Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: positional encoding\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the original paper, the authors add the positional encodings to the input embeddings at the bottom of both the encoder and decoder blocks so the model can have some information about the relative or absolute position of the tokens in the sequence. The positional encodings have the same dimension $d_{model}$ as the embeddings, so that the two vectors can be summed and we can combine the semantic content from the word embeddings and positional information from the positional encodings.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>PositionalEncoding</code> class below, we will create a matrix of positional encodings <code>pe</code> with dimensions <code>(seq_len, d_model)</code>. We will start by filling it with $0$s.We will then apply the sine function to even indices of the positional encoding matrix while the cosine function is applied to the odd ones.</p>\n",
        "\n",
        "<p style=\"\n",
        "    margin-bottom: 5;\n",
        "    font-size: 22px;\n",
        "    font-weight: 300;\n",
        "    font-family: 'Helvetica Neue', sans-serif;\n",
        "    color: #000000;\n",
        "  \">\n",
        "    \\begin{equation}\n",
        "    \\text{Odd Indices } (2i + 1): \\quad \\text{PE(pos, } 2i + 1) = \\cos\\left(\\frac{\\text{pos}}{10000^{2i / d_{model}}}\\right)\n",
        "    \\end{equation}\n",
        "</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We apply the sine and cosine functions because it allows the model to determine the position of a word based on the position of other words in the sequence, since for any fixed offset $k$, $PE_{pos + k}$ can be represented as a linear function of $PE_{pos}$. This happens due to the properties of sine and cosine functions, where a shift in the input results in a predictable change in the output.</p>"
      ],
      "metadata": {
        "id": "RWBlo2XorJGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.shape[1], :].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "4ZG5DhVcrVVm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:09.825342Z",
          "iopub.execute_input": "2025-01-05T15:59:09.825661Z",
          "iopub.status.idle": "2025-01-05T15:59:09.832555Z",
          "shell.execute_reply.started": "2025-01-05T15:59:09.825634Z",
          "shell.execute_reply": "2025-01-05T15:59:09.831396Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: layer normalization\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we look at the encoder and decoder blocks, we see several normalization layers called <b><i>Add &amp; Norm</i></b>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>LayerNormalization</code> class below performs layer normalization on the input data. During its forward pass, we compute the mean and standard deviation of the input data. We then normalize the input data by subtracting the mean and dividing by the standard deviation plus a small number called epsilon to avoid any divisions by zero. This process results in a normalized output with a mean 0 and a standard deviation 1.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will then scale the normalized output by a learnable parameter <code>alpha</code> and add a learnable parameter called <code>bias</code>. The training process is responsible for adjusting these parameters. The final result is a layer-normalized tensor, which ensures that the scale of the inputs to layers in the network is consistent.</p>"
      ],
      "metadata": {
        "id": "T92iydQErh-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, features: int, eps: float = 1e-6) -> None:\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.alpha = nn.Parameter(torch.ones(features))\n",
        "        self.bias = nn.Parameter(torch.zeros(features))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        return self.alpha * (x - mean) / (std + self.eps) + self.bias"
      ],
      "metadata": {
        "id": "kVGQRsmKrwZu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:13.320879Z",
          "iopub.execute_input": "2025-01-05T15:59:13.321232Z",
          "iopub.status.idle": "2025-01-05T15:59:13.326574Z",
          "shell.execute_reply.started": "2025-01-05T15:59:13.321202Z",
          "shell.execute_reply": "2025-01-05T15:59:13.325807Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Feed Forward Network\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the fully connected feed-forward network, we apply two linear transformations with a ReLU activation in between. We can mathematically represent this operation as:</p>\n",
        "\n",
        "<p style=\"\n",
        "    margin-bottom: 5;\n",
        "    font-size: 22px;\n",
        "    font-weight: 300;\n",
        "    font-family: 'Helvetica Neue', sans-serif;\n",
        "    color: #000000;\n",
        "  \">\n",
        "    \\begin{equation}\n",
        "    \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2\n",
        "    \\end{equation}\n",
        "</p>\n",
        "\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">$W_1$ and $W_2$ are the weights, while $b_1$ and $b_2$ are the biases of the two linear transformations.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>FeedForwardBlock</code> below, we will define the two linear transformations—<code>self.linear_1</code> and <code>self.linear_2</code>—and the inner-layer <code>d_ff</code>. The input data will first pass through the <code>self.linear_1</code> transformation, which increases its dimensionality from <code>d_model</code> to <code>d_ff</code>. The output of this operation passes through the ReLU activation function, which introduces non-linearity so the network can learn more complex patterns, and the <code>self.dropout</code> layer is applied to mitigate overfitting. The final operation is the <code>self.linear_2</code> transformation to the dropout-modified tensor, which transforms it back to the original <code>d_model</code> dimension.</p>"
      ],
      "metadata": {
        "id": "U-IbSGQMr1Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
      ],
      "metadata": {
        "id": "N3H8kyccsEUW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:16.740013Z",
          "iopub.execute_input": "2025-01-05T15:59:16.740353Z",
          "iopub.status.idle": "2025-01-05T15:59:16.745683Z",
          "shell.execute_reply.started": "2025-01-05T15:59:16.740324Z",
          "shell.execute_reply": "2025-01-05T15:59:16.744750Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Multi Head Attention\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The Multi-Head Attention is the most crucial component of the Transformer. It is responsible for helping the model to understand complex relationships and patterns in the data.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The image below displays how the Multi-Head Attention works. It doesn't include <code>batch</code> dimension because it only illustrates the process for one single sentence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The Multi-Head Attention block receives the input data split into queries, keys, and values organized into matrices $Q$, $K$, and $V$. Each matrix contains different facets of the input, and they have the same dimensions as the input.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We then linearly transform each matrix by their respective weight matrices $W^Q$, $W^K$, and $W^V$. These transformations will result in new matrices $Q'$, $K'$, and $V'$, which will be split into smaller matrices corresponding to different heads $h$, allowing the model to attend to information from different representation subspaces in parallel. This split creates multiple sets of queries, keys, and values for each head.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Finally, we concatenate every head into an $H$ matrix, which is then transformed by another weight matrix $W^o$ to produce the multi-head attention output, a matrix $MH-A$ that retains the input dimensionality.</p>"
      ],
      "metadata": {
        "id": "YEa1kF6csIvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.w_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_v = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.w_o = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
        "        attention_scores = attention_scores.softmax(dim=-1)\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        query = self.w_q(q)\n",
        "        key = self.w_k(k)\n",
        "        value = self.w_v(v)\n",
        "\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        x, self.attention_scores = self.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "        return self.w_o(x)"
      ],
      "metadata": {
        "id": "6ujcqPp1sOU9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:21.485903Z",
          "iopub.execute_input": "2025-01-05T15:59:21.486281Z",
          "iopub.status.idle": "2025-01-05T15:59:21.495506Z",
          "shell.execute_reply.started": "2025-01-05T15:59:21.486249Z",
          "shell.execute_reply": "2025-01-05T15:59:21.494615Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Residual Connection\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">When we look at the architecture of the Transformer, we see that each sub-layer, including the <i>self-attention</i> and <i>Feed Forward</i> blocks, adds its output to its input before passing it to the <i>Add &amp; Norm</i> layer. This approach integrates the output with the original input in the <i>Add &amp; Norm</i> layer. This process is known as the skip connection, which allows the Transformer to train deep networks more effectively by providing a shortcut for the gradient to flow through during backpropagation.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>ResidualConnection</code> class below is responsible for this process.</p>"
      ],
      "metadata": {
        "id": "wCaLjCVxsWIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, features: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = LayerNormalization(features)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "metadata": {
        "id": "f-bvuGhIsdfu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:26.560609Z",
          "iopub.execute_input": "2025-01-05T15:59:26.560891Z",
          "iopub.status.idle": "2025-01-05T15:59:26.565503Z",
          "shell.execute_reply.started": "2025-01-05T15:59:26.560869Z",
          "shell.execute_reply": "2025-01-05T15:59:26.564514Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7: Encoder\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will now build the encoder. We create the <code>EncoderBlock</code> class, consisting of the Multi-Head Attention and Feed Forward layers, plus the residual connections.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the original paper, the Encoder Block repeats six times. We create the <code>Encoder</code> class as an assembly of multiple <code>EncoderBlock</code>s. We also add layer normalization as a final step after processing the input through all its blocks.</p>"
      ],
      "metadata": {
        "id": "9YYI5vpasdGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
        "        x = self.residual_connections[1](x, self.feed_forward_block)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fRtppwE1s0-t",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:29.670722Z",
          "iopub.execute_input": "2025-01-05T15:59:29.671000Z",
          "iopub.status.idle": "2025-01-05T15:59:29.676573Z",
          "shell.execute_reply.started": "2025-01-05T15:59:29.670978Z",
          "shell.execute_reply": "2025-01-05T15:59:29.675670Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization(features)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "eSq7BZWcs5s1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:32.550327Z",
          "iopub.execute_input": "2025-01-05T15:59:32.550642Z",
          "iopub.status.idle": "2025-01-05T15:59:32.555441Z",
          "shell.execute_reply.started": "2025-01-05T15:59:32.550613Z",
          "shell.execute_reply": "2025-01-05T15:59:32.554517Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8: Decoder\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Similarly, the Decoder also consists of several DecoderBlocks that repeat six times in the original paper. The main difference is that it has an additional sub-layer that performs multi-head attention with a <i>cross-attention</i> component that uses the output of the Encoder as its keys and values while using the Decoder's input as queries.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">For the Output Embedding, we can use the same <code>InputEmbeddings</code> class we use for the Encoder. You can also notice that the self-attention sub-layer is <i>masked</i>, which restricts the model from accessing future elements in the sequence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will start by building the <code>DecoderBlock</code> class, and then we will build the <code>Decoder</code> class, which will assemble multiple <code>DecoderBlock</code>s.</p>"
      ],
      "metadata": {
        "id": "P0HXE1fH5g0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.cross_attention_block = cross_attention_block\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
        "        return x"
      ],
      "metadata": {
        "id": "V9Aof9mb4PJX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:40.320235Z",
          "iopub.execute_input": "2025-01-05T15:59:40.320571Z",
          "iopub.status.idle": "2025-01-05T15:59:40.326724Z",
          "shell.execute_reply.started": "2025-01-05T15:59:40.320543Z",
          "shell.execute_reply": "2025-01-05T15:59:40.325815Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization(features)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "vwdthvkrtNUM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:43.595055Z",
          "iopub.execute_input": "2025-01-05T15:59:43.595416Z",
          "iopub.status.idle": "2025-01-05T15:59:43.600364Z",
          "shell.execute_reply.started": "2025-01-05T15:59:43.595388Z",
          "shell.execute_reply": "2025-01-05T15:59:43.599363Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">You can see in the Decoder image that after running a stack of <code>DecoderBlock</code>s, we have a Linear Layer and a Softmax function to the output of probabilities. The <code>ProjectionLayer</code> class below is responsible for converting the output of the model into a probability distribution over the <i>vocabulary</i>, where we select each output token from a vocabulary of possible tokens.</p>"
      ],
      "metadata": {
        "id": "Qm4g_8O1tS3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.log_softmax(self.proj(x), dim=-1)"
      ],
      "metadata": {
        "id": "UbWVoNintThN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:46.959876Z",
          "iopub.execute_input": "2025-01-05T15:59:46.960245Z",
          "iopub.status.idle": "2025-01-05T15:59:46.964974Z",
          "shell.execute_reply.started": "2025-01-05T15:59:46.960215Z",
          "shell.execute_reply": "2025-01-05T15:59:46.963922Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 9: Building the Transformer\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We finally have every component of the Transformer architecture ready. We may now construct the Transformer by putting it all together.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>Transformer</code> class below, we will bring together all the components of the model's architecture.</p>"
      ],
      "metadata": {
        "id": "waCzPEAxtaR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        src = self.src_embed(src)\n",
        "        src = self.src_pos(src)\n",
        "        return self.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "        tgt = self.tgt_embed(tgt)\n",
        "        tgt = self.tgt_pos(tgt)\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    def project(self, x):\n",
        "        return self.projection_layer(x)"
      ],
      "metadata": {
        "id": "qXbPW4oCtk2G",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:50.022167Z",
          "iopub.execute_input": "2025-01-05T15:59:50.022469Z",
          "iopub.status.idle": "2025-01-05T15:59:50.028834Z",
          "shell.execute_reply.started": "2025-01-05T15:59:50.022446Z",
          "shell.execute_reply": "2025-01-05T15:59:50.027796Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The architecture is finally ready. We now define a function called <code>build_transformer</code>, in which we define the parameters and everything we need to have a fully operational Transformer model for the task of <b>machine translation</b>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will set the same parameters as in the original paper, <a href = \"https://arxiv.org/pdf/1706.03762.pdf\"><i>Attention Is All You Need</i></a>, where $d_{model}$ = 512, $N$ = 6, $h$ = 8, dropout rate $P_{drop}$ = 0.1, and $d_{ff}$ = 2048.</p>"
      ],
      "metadata": {
        "id": "6znypMaetmRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int = 512, N: int = 6, h: int = 8, dropout: float = 0.1, d_ff: int = 2048) -> Transformer:\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    encoder_blocks = [\n",
        "        EncoderBlock(\n",
        "            d_model,\n",
        "            MultiHeadAttentionBlock(d_model, h, dropout),\n",
        "            FeedForwardBlock(d_model, d_ff, dropout),\n",
        "            dropout\n",
        "        ) for _ in range(N)\n",
        "    ]\n",
        "\n",
        "    decoder_blocks = [\n",
        "        DecoderBlock(\n",
        "            d_model,\n",
        "            MultiHeadAttentionBlock(d_model, h, dropout),\n",
        "            MultiHeadAttentionBlock(d_model, h, dropout),\n",
        "            FeedForwardBlock(d_model, d_ff, dropout),\n",
        "            dropout\n",
        "        ) for _ in range(N)\n",
        "    ]\n",
        "\n",
        "    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return transformer"
      ],
      "metadata": {
        "id": "bqGnJ6w2twJc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:54.036808Z",
          "iopub.execute_input": "2025-01-05T15:59:54.037168Z",
          "iopub.status.idle": "2025-01-05T15:59:54.044465Z",
          "shell.execute_reply.started": "2025-01-05T15:59:54.037107Z",
          "shell.execute_reply": "2025-01-05T15:59:54.043552Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is now ready to be trained!"
      ],
      "metadata": {
        "id": "Iw7CWf4bt3yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 10: Tokenizer"
      ],
      "metadata": {
        "id": "6_7Z3fEYuTK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Tokenization is a crucial preprocessing step for our Transformer model. In this step, we convert raw text into a number format that the model can process.  </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">There are several Tokenization strategies. We will use the <i>word-level tokenization</i> to transform each word in a sentence into a token.</p>"
      ],
      "metadata": {
        "id": "EDinqTghqr_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <img src = \"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8d5e749c-b0bd-4496-85a1-9b4397ad935f_1400x787.jpeg\" width = 800, height= 800>\n",
        "<p style = \"font-size: 16px;\n",
        "            font-family: 'Georgia', serif;\n",
        "            text-align: center;\n",
        "            margin-top: 10px;\">Different tokenization strategies. Source: <a href = \"https://shaankhosla.substack.com/p/talking-tokenization\">shaankhosla.substack.com</a>.</p>\n",
        "</center>"
      ],
      "metadata": {
        "id": "at-cYYjnqr_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">After tokenizing a sentence, we map each token to an unique integer ID based on the created vocabulary present in the training corpus during the training of the tokenizer. Each integer number represents a specific word in the vocabulary.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Besides the words in the training corpus, Transformers use special tokens for specific purposes. These are some that we will define right away:</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>• [UNK]:</b> This token is used to identify an unknown word in the sequence.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>• [PAD]:</b> Padding token to ensure that all sequences in a batch have the same length, so we pad shorter sentences with this token. We use attention masks to <i>\"tell\"</i> the model to ignore the padded tokens during training since they don't have any real meaning to the task.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>•  [SOS]:</b> This is a token used to signal the <i>Start of Sentence</i>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\"><b>•  [EOS]:</b> This is a token used to signal the <i>End of Sentence</i>.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>build_tokenizer</code> function below, we ensure a tokenizer is ready to train the model. It checks if there is an existing tokenizer, and if that is not the case, it trains a new tokenizer.</p>"
      ],
      "metadata": {
        "id": "gjRMr2N6qr_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_or_build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
        "    if not tokenizer_path.exists():\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "Zh9pOItduxHq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T15:59:59.432552Z",
          "iopub.execute_input": "2025-01-05T15:59:59.432851Z",
          "iopub.status.idle": "2025-01-05T15:59:59.438229Z",
          "shell.execute_reply.started": "2025-01-05T15:59:59.432826Z",
          "shell.execute_reply": "2025-01-05T15:59:59.437188Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 11: Load Dataset"
      ],
      "metadata": {
        "id": "oodlr4eouxTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">For this task, we will use the <a href = \"opus_books · Datasets at Hugging Face\">OpusBooks dataset</a>, available on 🤗Hugging Face. This dataset consists of two features, <code>id</code> and <code>translation</code>. The <code>translation</code> feature contains pairs of sentences in different languages, such as Spanish and Portuguese, English and French, and so forth.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">I first tried translating sentences from English to Portuguese—my native tongue — but there are only 1.4k examples for this pair, so the results were not satisfying in the current configurations for this model. I then tried to use the English-French pair due to its higher number of examples—127k—but it would take too long to train with the current configurations. I then opted to train the model on the English-Italian pair, the same one used in the <a href = \"https://youtu.be/ISNdQcPhsts?si=253J39cose6IdsLv\">Coding a Transformer from scratch on PyTorch, with full explanation, training and inference\n",
        "</a> video, as that was a good balance between performance and time of training.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We start by defining the <code>get_all_sentences</code> function to iterate over the dataset and extract the sentences according to the language pair defined—we will do that later.</p>"
      ],
      "metadata": {
        "id": "YdVFowgUqr_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_sentences(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]"
      ],
      "metadata": {
        "id": "xvRuuTpIveZS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:00:03.211260Z",
          "iopub.execute_input": "2025-01-05T16:00:03.211608Z",
          "iopub.status.idle": "2025-01-05T16:00:03.215543Z",
          "shell.execute_reply.started": "2025-01-05T16:00:03.211579Z",
          "shell.execute_reply": "2025-01-05T16:00:03.214808Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>get_ds</code> function is defined to load and prepare the dataset for training and validation. In this function, we build or load the tokenizer, split the dataset, and create DataLoaders, so the model can successfully iterate over the dataset in batches. The result of these functions is tokenizers for the source and target languages plus the DataLoader objects.</p>"
      ],
      "metadata": {
        "id": "EA13IRYEqr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ds(config):\n",
        "    ds_raw = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n",
        "\n",
        "    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n",
        "    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
        "\n",
        "    train_ds_size = int(0.9 * len(ds_raw))\n",
        "    val_ds_size = len(ds_raw) - train_ds_size\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "    max_len_src = max(len(tokenizer_src.encode(item['translation'][config['lang_src']]).ids) for item in ds_raw)\n",
        "    max_len_tgt = max(len(tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids) for item in ds_raw)\n",
        "\n",
        "    print(f'Max length of source sentence: {max_len_src}')\n",
        "    print(f'Max length of target sentence: {max_len_tgt}')\n",
        "\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt"
      ],
      "metadata": {
        "id": "IkTRqP8LvpVy",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:17.750052Z",
          "iopub.execute_input": "2025-01-05T16:01:17.750380Z",
          "iopub.status.idle": "2025-01-05T16:01:17.757450Z",
          "shell.execute_reply.started": "2025-01-05T16:01:17.750357Z",
          "shell.execute_reply": "2025-01-05T16:01:17.756609Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We define the <code>casual_mask</code> function to create a mask for the attention mechanism of the decoder. This mask prevents the model from having information about future elements in the sequence. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We start by making a square grid filled with ones. We determine the grid size with the <code>size</code> parameter. Then, we change all the numbers above the main diagonal line to zeros. Every number on one side becomes a zero, while the rest remain ones. The function then flips all these values, turning ones into zeros and zeros into ones. This process is crucial for models that predict future tokens in a sequence.</p>"
      ],
      "metadata": {
        "id": "VK3d2-AVqr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0"
      ],
      "metadata": {
        "id": "kTgMYaY2vvWq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:21.825338Z",
          "iopub.execute_input": "2025-01-05T16:01:21.825639Z",
          "iopub.status.idle": "2025-01-05T16:01:21.829721Z",
          "shell.execute_reply.started": "2025-01-05T16:01:21.825616Z",
          "shell.execute_reply": "2025-01-05T16:01:21.828807Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>BilingualDataset</code> class processes the texts of the target and source languages in the dataset by tokenizing them and adding all the necessary special tokens. This class also certifies that the sentences are within a maximum sequence length for both languages and pads all necessary sentences.</p>"
      ],
      "metadata": {
        "id": "ccdK5XnMqr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualDataset(Dataset):\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.ds = ds\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "\n",
        "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_target_pair = self.ds[idx]\n",
        "        src_text = src_target_pair['translation'][self.src_lang]\n",
        "        tgt_text = src_target_pair['translation'][self.tgt_lang]\n",
        "\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2\n",
        "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n",
        "\n",
        "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "            raise ValueError(\"Sentence is too long\")\n",
        "\n",
        "        encoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        decoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        label = torch.cat(\n",
        "            [\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        assert encoder_input.size(0) == self.seq_len\n",
        "        assert decoder_input.size(0) == self.seq_len\n",
        "        assert label.size(0) == self.seq_len\n",
        "\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input,\n",
        "            \"decoder_input\": decoder_input,\n",
        "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n",
        "            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & causal_mask(decoder_input.size(0)),\n",
        "            \"label\": label,\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }"
      ],
      "metadata": {
        "id": "x9v94mdgv3y6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:28.252664Z",
          "iopub.execute_input": "2025-01-05T16:01:28.252943Z",
          "iopub.status.idle": "2025-01-05T16:01:28.262531Z",
          "shell.execute_reply.started": "2025-01-05T16:01:28.252921Z",
          "shell.execute_reply": "2025-01-05T16:01:28.261690Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 12: Validation Loop"
      ],
      "metadata": {
        "id": "B7cXlNUfv5uL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will now create two functions for the validation loop. The validation loop is crucial to evaluate model performance in translating sentences from data it has not seen during training.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We will define two functions. The first function, <code>greedy_decode</code>, gives us the model's output by obtaining the most probable next token. The second function, <code>run_validation</code>, is responsible for running the validation process in which we decode the model's output and compare it with the reference text for the target sentence.</p>"
      ],
      "metadata": {
        "id": "tf8Wt860qr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    encoder_output = model.encode(source, source_mask)\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "\n",
        "    while decoder_input.size(1) < max_len:\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "        prob = model.project(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        decoder_input = torch.cat(\n",
        "            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n",
        "        )\n",
        "\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "\n",
        "    return decoder_input.squeeze(0)"
      ],
      "metadata": {
        "id": "z1rzcAkpv8Ew",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:32.191588Z",
          "iopub.execute_input": "2025-01-05T16:01:32.191867Z",
          "iopub.status.idle": "2025-01-05T16:01:32.198155Z",
          "shell.execute_reply.started": "2025-01-05T16:01:32.191846Z",
          "shell.execute_reply": "2025-01-05T16:01:32.197210Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_step, writer, num_examples=2):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    source_texts = []\n",
        "    expected = []\n",
        "    predicted = []\n",
        "\n",
        "    try:\n",
        "        with os.popen('stty size', 'r') as console:\n",
        "            _, console_width = console.read().split()\n",
        "            console_width = int(console_width)\n",
        "    except:\n",
        "        console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "            source_text = batch[\"src_text\"][0]\n",
        "            target_text = batch[\"tgt_text\"][0]\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            source_texts.append(source_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            print_msg('-' * console_width)\n",
        "            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "\n",
        "            if count == num_examples:\n",
        "                print_msg('-' * console_width)\n",
        "                break\n",
        "\n",
        "    if writer:\n",
        "        metric = torchmetrics.CharErrorRate()\n",
        "        cer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation cer', cer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        metric = torchmetrics.WordErrorRate()\n",
        "        wer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation wer', wer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        metric = torchmetrics.BLEUScore()\n",
        "        bleu = metric(predicted, expected)\n",
        "        writer.add_scalar('validation BLEU', bleu, global_step)\n",
        "        writer.flush()"
      ],
      "metadata": {
        "id": "iF7v9L0owcLT",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:35.480923Z",
          "iopub.execute_input": "2025-01-05T16:01:35.481273Z",
          "iopub.status.idle": "2025-01-05T16:01:35.489772Z",
          "shell.execute_reply.started": "2025-01-05T16:01:35.481241Z",
          "shell.execute_reply": "2025-01-05T16:01:35.488761Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 13: Training Loop"
      ],
      "metadata": {
        "id": "qw3nykKxwkIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We are ready to train our Transformer model on the OpusBook dataset for the English to Italian translation task.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We first start by defining the <code>get_model</code> function to load the model by calling the <code>build_transformer</code> function we have previously defined. This function uses the <code>config</code> dictionary to set a few parameters.</p>"
      ],
      "metadata": {
        "id": "az_Kwq4Zqr_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config[\"seq_len\"], d_model=config[\"d_model\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "7QMn1BULwnBl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:39.365382Z",
          "iopub.execute_input": "2025-01-05T16:01:39.365672Z",
          "iopub.status.idle": "2025-01-05T16:01:39.369626Z",
          "shell.execute_reply.started": "2025-01-05T16:01:39.365650Z",
          "shell.execute_reply": "2025-01-05T16:01:39.368917Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">I have mentioned the <code>config</code> dictionary several times throughout this notebook. Now, it is time to create it.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the following cell, we will define two functions to configure our model and the training process.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In the <code>get_config</code> function, we define crucial parameters for the training process. <code>batch_size</code> for the number of training examples used in one iteration, <code>num_epochs</code> as the number of times the entire dataset is passed forward and backward through the Transformer, <code>lr</code> as the learning rate for the optimizer, etc. We will also finally define the pairs from the OpusBook dataset, <code>'lang_src': 'en'</code> for selecting English as the source language and <code>'lang_tgt': 'it'</code> for selecting Italian as the target language.</p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">The <code>get_weights_file_path</code> function constructs the file path for saving or loading model weights for any specific epoch.</p>"
      ],
      "metadata": {
        "id": "Ord2DlVkqr_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_config():\n",
        "    return {\n",
        "        \"batch_size\": 8,\n",
        "        \"num_epochs\": 15,\n",
        "        \"lr\": 1e-4,\n",
        "        \"seq_len\": 350,\n",
        "        \"d_model\": 512,\n",
        "        \"datasource\": \"opus_books\",\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"it\",\n",
        "        \"model_folder\": \"weights\",\n",
        "        \"model_basename\": \"tmodel_\",\n",
        "        \"preload\": \"latest\",\n",
        "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "        \"experiment_name\": \"runs/tmodel\",\n",
        "    }\n",
        "\n",
        "def get_weights_file_path(config, epoch: str):\n",
        "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
        "    return str(Path(\".\") / model_folder / f\"{config['model_basename']}{epoch}.pt\")\n",
        "\n",
        "def latest_weights_file_path(config):\n",
        "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
        "    weights_files = sorted(Path(model_folder).glob(f\"{config['model_basename']}*\"))\n",
        "    return str(weights_files[-1]) if weights_files else None"
      ],
      "metadata": {
        "id": "gXt82CejxeHZ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:18:07.990158Z",
          "iopub.execute_input": "2025-01-05T16:18:07.990450Z",
          "iopub.status.idle": "2025-01-05T16:18:07.996078Z",
          "shell.execute_reply.started": "2025-01-05T16:18:07.990426Z",
          "shell.execute_reply": "2025-01-05T16:18:07.995223Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">We finally define our last function, <code>train_model</code>, which takes the <code>config</code> arguments as input. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">In this function, we will set everything up for the training. We will load the model and its necessary components onto the GPU for faster training, set the <code>Adam</code> optimizer, and configure the <code>CrossEntropyLoss</code> function to compute the differences between the translations output by the model and the reference translations from the dataset. </p>\n",
        "\n",
        "<p style = \"font-family: 'Helvetica Neue', Arial, sans-serif; text-align: left; font-size: 17.5px\">Every loop necessary for iterating over the training batches, performing backpropagation, and computing the gradients is in this function. We will also use it to run the validation function and save the current state of the model.</p>"
      ],
      "metadata": {
        "id": "Qw7SjmrDqr_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(config):\n",
        "    device = (\n",
        "        \"cuda\" if torch.cuda.is_available()\n",
        "        else \"mps\" if torch.has_mps or torch.backends.mps.is_available()\n",
        "        else \"cpu\"\n",
        "    )\n",
        "    print(f\"Using device: {device}\")\n",
        "    if device == \"cuda\":\n",
        "        print(f\"Device name: {torch.cuda.get_device_name()}\")\n",
        "        print(f\"Device memory: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB\")\n",
        "    device = torch.device(device)\n",
        "\n",
        "    weights_dir = Path(f\"{config['datasource']}_{config['model_folder']}\")\n",
        "    weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "    writer = SummaryWriter(config['experiment_name'])\n",
        "    optimizer = Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "    initial_epoch, global_step = 0, 0\n",
        "    model_filename = (\n",
        "        latest_weights_file_path(config)\n",
        "        if config['preload'] == 'latest'\n",
        "        else get_weights_file_path(config, config['preload'])\n",
        "        if config['preload'] else None\n",
        "    )\n",
        "\n",
        "    if model_filename:\n",
        "        print(f'Preloading model from {model_filename}')\n",
        "        checkpoint = torch.load(model_filename)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        initial_epoch = checkpoint['epoch'] + 1\n",
        "        global_step = checkpoint['global_step']\n",
        "    else:\n",
        "        print(\"No pretrained model found, starting from scratch.\")\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, config['num_epochs']):\n",
        "        torch.cuda.empty_cache()\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{config['num_epochs']}\")\n",
        "\n",
        "        for batch in batch_iterator:\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            decoder_input = batch['decoder_input'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "            proj_output = model.project(decoder_output)\n",
        "\n",
        "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), labels.view(-1))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            writer.add_scalar('train loss', loss.item(), global_step)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            global_step += 1\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "        run_validation(\n",
        "            model, val_dataloader, tokenizer_src, tokenizer_tgt,\n",
        "            config['seq_len'], device, lambda msg: batch_iterator.write(msg),\n",
        "            global_step, writer\n",
        "        )\n",
        "\n",
        "        model_path = get_weights_file_path(config, f\"{epoch:02d}\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_path)\n",
        "        print(f\"Model saved at {model_path}\")"
      ],
      "metadata": {
        "id": "2qK9wAjRxoDQ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:01:47.296952Z",
          "iopub.execute_input": "2025-01-05T16:01:47.297301Z",
          "iopub.status.idle": "2025-01-05T16:01:47.308638Z",
          "shell.execute_reply.started": "2025-01-05T16:01:47.297272Z",
          "shell.execute_reply": "2025-01-05T16:01:47.307824Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now train the model!"
      ],
      "metadata": {
        "id": "nrMmfyi8xrXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    warnings.filterwarnings('ignore')\n",
        "    config = get_config()\n",
        "    train_model(config)\n",
        "    pass"
      ],
      "metadata": {
        "id": "28425EYaxrsi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "d0277472866944fbae6a4f8c3d204c3d",
            "4d47670e4aa24d92b9a26dbfbb46cba5",
            "2a1d993cd4314f85b68341220ee8b585",
            "6834db95fa3b45c18df5b4b8dca50cbc",
            "e80d405bcce5452b824bbfbd26400ca5",
            "113bcee4a2a84c7d864cf6e79d844ac5",
            "b9fd3a1495414eb8afa2f76b5ff6078b",
            "c9236224bf234c85a6e370779240afb5",
            "7c4275a4a2be4e26a71ae9bbce973b45",
            "f941fe0e14ee4845a175d293c6d826d8",
            "49e8ae1a041f46d6800106a2d5e6f9c9",
            "2f5bd351e9d34e79b514ca4e7cc85c01",
            "cdcbe3ad4edf405aa561e68c16b05388",
            "c581862600a04811a781880cfb63f2f3",
            "fd3b7fb2719e4a8b8fa4e53da171f60f",
            "598342248f5a4916b146388c3de8ddfc",
            "f2858b9dc5774a22a7db0a96d71e0056",
            "f86b36dc5b53425096222cb630539690",
            "2af53704dc6142adaa0b418f9f8fdec3",
            "d58a4e4677d64f048a47ae28e79cbe76",
            "749c8864bf584033b0c4fc081d220a12",
            "3f96fdc89c5e414f8c5f7f4f0c25908e",
            "126087714091462ea671f937a1008971",
            "9ea157093fc7424c932db9f8bf4f1054",
            "767026d8aafa4992b610484f568a4d85",
            "cf3c396376f44621a348bac68d2521c4",
            "2437e77564d34e5eb39067fc6d403ae6",
            "ff1ef2e0cb824a60896150598514df3c",
            "9ccb431b0d45443a9ed619800327b096",
            "aaab2016f3d547eba8027f6853fb79d7",
            "51c51faa4cd94706bd5acc5fd73df56c",
            "7e714f39277f4028bfdf00f8805d3725",
            "5569955af7c447efae4b5642787a390f"
          ]
        },
        "outputId": "bc729ef3-5fbc-4622-de5a-e849ba4ffe62",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-05T16:18:13.950248Z",
          "iopub.execute_input": "2025-01-05T16:18:13.950555Z",
          "iopub.status.idle": "2025-01-05T19:50:13.240493Z",
          "shell.execute_reply.started": "2025-01-05T16:18:13.950523Z",
          "shell.execute_reply": "2025-01-05T19:50:13.239730Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\nDevice name: Tesla P100-PCIE-16GB\nDevice memory: 15.887939453125 GB\nMax length of source sentence: 309\nMax length of target sentence: 274\nPreloading model opus_books_weights/tmodel_00.pt\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 01: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=5.731]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: I said I'd pack.\n    TARGET: Dissi che avrei fatto il bagaglio io.\n PREDICTED: Io mi pare che mi .\n--------------------------------------------------------------------------------\n    SOURCE: She, he thought, would cast no stones, but would simply and resolutely go and see Anna and receive her at her own house.\n    TARGET: Gli sembrava che non avrebbe scagliato lei la prima pietra, e con semplicità e franchezza sarebbe andata da Anna e l’avrebbe ricevuta.\n PREDICTED: Egli , non aveva detto , ma non aveva detto , e non aveva detto che egli aveva detto , e si sentiva a lei .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 02: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=5.369]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: It was impossible not to smile, not to kiss the little thing; impossible not to hold out a finger to her, which she caught, screaming and wriggling the whole surface of her little body; impossible not to approach one's lips to her mouth and let her draw them in, her way of kissing.\n    TARGET: Non si poteva non sorridere, non baciare la piccola; non si poteva non tenderle un dito al quale ella si aggrappò stringendo e sussultando in tutto il corpo; non si poteva non tenderle il labbro ch’ella afferrò nella piccola bocca a mo’ di bacio.\n PREDICTED: Non era nulla di nuovo , non solo il suo sorriso , non si , non si , e non si , e , il suo sguardo , e , senza , e non si , e non si , e non si .\n--------------------------------------------------------------------------------\n    SOURCE: A bolder hand might have turned the game even at that point.\n    TARGET: Una mano più ardita avrebbe anche a questo punto sconvolto il giuoco.\n PREDICTED: Una volta che il capo era stato di nuovo .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 03: 100%|██████████| 3638/3638 [15:06<00:00,  4.01it/s, loss=5.057]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: Another five minutes went by, and then I asked her to look again.\n    TARGET: Passarono altri cinque minuti, e poi le dissi di guardare ancora.\n PREDICTED: Un quarto di poco dopo , e io mi a casa .\n--------------------------------------------------------------------------------\n    SOURCE: Kitty remained silent.\n    TARGET: Kitty taceva.\n PREDICTED: Kitty si fermò .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 04: 100%|██████████| 3638/3638 [15:06<00:00,  4.01it/s, loss=5.628]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: Levin saw no one and nothing; he did not take his eyes off his bride.\n    TARGET: Levin non notava nulla e nessuno; senza abbassar gli occhi, guardava la sposa.\n PREDICTED: Levin non vedeva nulla e non lo guardò con la sua mano .\n--------------------------------------------------------------------------------\n    SOURCE: 'What's in it?' said the Queen.\n    TARGET: — Che contiene? — domandò la Regina\n PREDICTED: — Che cosa è ? — disse la Regina .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 05: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=3.472]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: Dolly told Masha's crime.\n    TARGET: — E Dar’ja Aleksandrovna raccontò il delitto di Maša.\n PREDICTED: Dolly disse : — Dolly .\n--------------------------------------------------------------------------------\n    SOURCE: It was about a young girl who lived in the Hartz Mountains, and who had given up her life to save her lover's soul; and he died, and met her spirit in the air; and then, in the last verse, he jilted her spirit, and went on with another spirit - I'm not quite sure of the details, but it was something very sad, I know.\n    TARGET: Parlava d’una fanciulla che abitava nelle montagne dell’Hartz, e che aveva dato la vita per salvare quella dell’innamorato: questi, poi, aveva incontrato lo spirito di lei in aria; quindi, nell’ultima strofa, egli respingeva lo spirito della fanciulla, e se ne andava con lo spirito d’un’altra.\n PREDICTED: Era una bambina che aveva fatto un giovane e che aveva fatto il suo amore e che aveva fatto la sua vita , e la sua anima sua , e la sua anima era stata in lei , e non ne sono in un ’ altra , ma con la sua gioia .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 06: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=3.837]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: Levin could not at all understand what was the matter, and was astounded at the ardour with which they discussed the question whether Flerov's case should be put to the ballot or not.\n    TARGET: Levin non riusciva in nessun modo a capire di che si trattasse e si stupiva della passionalità con cui si esaminava la questione se mettere o no ai voti la opinione su Flerov.\n PREDICTED: Levin non poteva non capire quello che era quello che voleva fare e che si con la questione della questione che si doveva fare o che si sarebbe dovuto fare o non si poteva far nulla .\n--------------------------------------------------------------------------------\n    SOURCE: Kitty did not say a word of this; she spoke only of her state of mind.\n    TARGET: Ma Kitty non disse neppure una parola di questo. Parlava solo delle sue condizioni di spirito.\n PREDICTED: Kitty non diceva una parola di questa parola , ma le parole di lei lo diceva .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 07: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=2.816]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: 'That's the reason they're called lessons,' the Gryphon remarked: 'because they lessen from day to day.'\n    TARGET: — Ma è questa la ragione perchè si chiamano lezioni, — osservò il Grifone: — perchè c'è una lesione ogni giorno.\n PREDICTED: — È la ragione del tutto , — disse il Grifone , — perché hanno il giorno , perché si il giorno .\n--------------------------------------------------------------------------------\n    SOURCE: These I set up to dry within my circle or hedge, and when they were fit for use I carried them to my cave; and here, during the next season, I employed myself in making, as well as I could, a great many baskets, both to carry earth or to carry or lay up anything, as I had occasion; and though I did not finish them very handsomely, yet I made them sufficiently serviceable for my purpose; thus, afterwards, I took care never to be without them; and as my wicker-ware decayed, I made more, especially strong, deep baskets to place my corn in, instead of sacks, when I should come to have any quantity of it.\n    TARGET: Non dirò che fossero estremamente eleganti, ma servivano al proposito per cui me gli aveva fatti. D’allora in poi procurai sempre d’averne una scorta, e quando i primi cominciavano ad essere logori, me ne faceva degli altri; principalmente ne fabbricai di ben profondi, perchè mi facessero vece di sacca, entro cui mettere il mio grano quando giugnessi ad averne un abbondante ricolto.\n PREDICTED: Questi miei affari mi in terra , e quando erano , e quando mi a bordo del mio vascello , mi in appresso di mia mente , mi in appresso di non avere a bordo una grande quantità di tali stromenti per , o per in appresso a tale distanza , o per in appresso di non aver avuto il mio grano , perchè io non fossi stato affatto in appresso di , come se non fossi stato , mi fossi stato fatto in appresso di , e non mi fossi stato più di que ’ miei , come io .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 08: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=4.325]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: One memory after another, both joyful and painful, rose in her mind, and for a moment she forgot why she had come.\n    TARGET: Uno dietro l’altro i ricordi, felici e tormentosi, si sollevarono nell’animo suo, e per un attimo ella dimenticò perché si trovava là.\n PREDICTED: Un ricordo dopo un altro , un ’ altra gioia e l ’ agitazione , e nello stesso tempo si sentì un attimo di esitazione .\n--------------------------------------------------------------------------------\n    SOURCE: And remembering how when he met him he had corrected the young man's use of a word that betrayed ignorance Koznyshev found an explanation of the article.\n    TARGET: E ricordatosi come, nell’incontro, avesse corretto quel giovane in una parola che rivelava la sua ignoranza, Sergej Ivanovic trovò la spiegazione del senso dell’articolo.\n PREDICTED: E ricordò come egli avesse detto che era stato detto al giovane russo , che aveva detto una parola di Sergej Ivanovic , la quale aveva preso la spiegazione del suo articolo .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 09: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=3.236]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: 'Oh, but we are not talking about that,' said Kitty, blushing.\n    TARGET: — Ma non parliamo di questo — disse Kitty, arrossendo.\n PREDICTED: — Ah , ma noi non parliamo più — disse Kitty , arrossendo .\n--------------------------------------------------------------------------------\n    SOURCE: I have been bothering about it a long time.\n    TARGET: Ho dovuto faticare per averlo.\n PREDICTED: Mi sono per un tempo .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 10: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=4.410]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: \"That I am not Edward Rochester's bride is the least part of my woe,\" I alleged: \"that I have wakened out of most glorious dreams, and found them all void and vain, is a horror I could bear and master; but that I must leave him decidedly, instantly, entirely, is intolerable.\n    TARGET: — Non poter essere più la sposa di Edoardo Rochester, — aggiunsi, — ecco il mio supplizio; svegliarmi dal più dolce dei sogni per non trovare intorno a me altro che vuoto e tristezza, ecco quello che posso ancora sopportare; ma doverlo lasciare risolutamente, subito per sempre, è intollerabile.\n PREDICTED: — Non sono il signor Edoardo , — interruppe la parte dei miei , — che sono le mie idee , e non potrei , ma tutti i piaceri di pensiero e non posso ; mi sono , ma è un aspetto volgare , che lo so .\n--------------------------------------------------------------------------------\n    SOURCE: \"_You_,\" I said, \"a favourite with Mr. Rochester? _You_ gifted with the power of pleasing him? _You_ of importance to him in any way?\n    TARGET: — Tu, — dissi, — la preferita del signor Rochester? Tu, avere il potere di piacergli?\n PREDICTED: — Mi sono , — dissi , — che il signor Rochester abbia il potere di in lui ?\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 11: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=3.755]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: His comrades had wakened long before and had had time to get hungry and have their breakfast.\n    TARGET: I compagni s’erano svegliati da un pezzo e avevano avuto il tempo di farsi venir fame e di far colazione.\n PREDICTED: I suoi compagni di pranzo prima che prima erano stati e avrebbero portato la colazione .\n--------------------------------------------------------------------------------\n    SOURCE: He said he couldn't say for certain of course, but that he rather thought he was.\n    TARGET: Rispose di non poterlo dire sicuramente, ma inclinava piuttosto per il sì.\n PREDICTED: Disse che non sapeva nulla di straordinario , ma che credeva che egli fosse un poco .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 12: 100%|██████████| 3638/3638 [15:05<00:00,  4.02it/s, loss=2.608]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: Georgiana said she dreaded being left alone with Eliza; from her she got neither sympathy in her dejection, support in her fears, nor aid in her preparations; so I bore with her feeble-minded wailings and selfish lamentations as well as I could, and did my best in sewing for her and packing her dresses.\n    TARGET: Georgiana diceva di non voler rimanere sola con sua sorella, perché non poteva trovare in lei né simpatia nel dolore, né appoggio nei suoi dolori, né aiuto nei suoi preparativi.\n PREDICTED: Georgiana mi disse che era rimasta sola con lei , Elisa e non aveva né tenerezza né tenerezza né tenerezza né tenerezza né tenerezza né tenerezza né tenerezza né la sua ammirazione , e che potesse meglio per le sue .\n--------------------------------------------------------------------------------\n    SOURCE: So it would be more correct to say that women are seeking for duties, and quite rightly.\n    TARGET: E perciò è più giusto dire che le donne cercano dei doveri, e del tutto legittimamente.\n PREDICTED: Così sarebbe più difficile dire che le donne sono dette alle donne , e che sono così semplici .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 13: 100%|██████████| 3638/3638 [15:06<00:00,  4.01it/s, loss=2.333]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: Because there is nothing proportionate between the armed and the unarmed; and it is not reasonable that he who is armed should yield obedience willingly to him who is unarmed, or that the unarmed man should be secure among armed servants.\n    TARGET: Perché da uno armato a uno disarmato non è proporzione alcuna; e non è ragionevole che chi è armato obedisca volentieri a chi è disarmato, e che il disarmato stia sicuro intra servitori armati.\n PREDICTED: Perché non c ’ è nulla di particolare , di e di , non è che sia ragionevole che , sia quello che si acquista , o si , o si , o si le signore che si in grandi soldati .\n--------------------------------------------------------------------------------\n    SOURCE: But why does he not come?\n    TARGET: Ma come mai non viene?\n PREDICTED: Ma perché non è venuto ?\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing Epoch 14: 100%|██████████| 3638/3638 [15:06<00:00,  4.01it/s, loss=2.712]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------------------------------------------------------------------------\n    SOURCE: And she wrote out a telegram.\n    TARGET: E scrisse un telegramma:\n PREDICTED: E scrisse un telegramma .\n--------------------------------------------------------------------------------\n    SOURCE: We tried to get away from it at Marlow.\n    TARGET: Provammo a fuggire e a riparare a Marlow.\n PREDICTED: Ne fuori per il percorso .\n--------------------------------------------------------------------------------\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: BERT and LoRA\n",
        "\n",
        "Welcome to Section 2 of our Machine Learning assignment! I hope you've been enjoying the journey so far! 😊\n",
        "\n",
        " In this section, you will gain hands-on experience with [BERT](https://arxiv.org/abs/1810.04805) (Bidirectional Encoder Representations from Transformers) and [LoRA](https://arxiv.org/abs/2106.09685) (Low-Rank Adaptation) for text classification tasks. The section is divided into three main parts, each focusing on different aspects of NLP techniques.\n",
        "\n",
        "## Assignment Structure\n",
        "\n",
        "### Part 1: Data Preparation and Preprocessing\n",
        "In this part, you will work with a text classification dataset. You will learn how to:\n",
        "- Download and load the dataset\n",
        "- Perform necessary preprocessing steps\n",
        "- Implement data cleaning and transformation techniques\n",
        "- Prepare the data in a format suitable for BERT training\n",
        "\n",
        "### Part 2: Building a Small BERT Model\n",
        "You will create and train a small BERT model from scratch using the Hugging Face [Transformers](https://huggingface.co/docs/transformers/en/index) library. This part will help you understand:\n",
        "- The architecture of BERT\n",
        "- How to configure and initialize a BERT model\n",
        "- Training process and optimization\n",
        "- Model evaluation and performance analysis\n",
        "\n",
        "### Part 3: Fine-tuning with LoRA\n",
        "In the final part, you will work with a pre-trained [TinyBERT](https://arxiv.org/abs/1909.10351) model and use LoRA for efficient fine-tuning. You will:\n",
        "- Load a pre-trained TinyBERT model\n",
        "- Implement LoRA adaptation and fine-tune the model on our classification task\n",
        "- Compare the results with the previous approach"
      ],
      "metadata": {
        "id": "v3axMN7QWiVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "> **NOTE**:  \n",
        "> Throughout this notebook, make an effort to include sufficient visualizations to enhance understanding:  \n",
        "> - In the data processing section, display the results of your operations (e.g., show data samples or distributions after preprocessing).  \n",
        "> - In the classification section, report various evaluation metrics such as accuracy, precision, recall, and F1-score to thoroughly assess your model's performance.  \n",
        "> - Additionally, take a moment to compare the sizes of the models discussed in this notebook with today’s enormous models. This will help you appreciate the challenges and computational demands associated with training such massive models. 😵‍💫\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "M6FKcSFbOTMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Data Preparation and Preprocessing\n",
        "We'll be working with the [Consumer Complaint](https://catalog.data.gov/dataset/consumer-complaint-database) dataset, which contains ***complaints*** submitted by consumers about financial products and services. Our goal is to build a classifier that can automatically identify the type of complaint based on the consumer's text description. For this task, we will work with a smaller subset of the dataset, available for download through this [link](https://drive.google.com/file/d/1SpIHksR-WzruEgUjp1SQKGG8bZPnJJoN/view?usp=sharing)."
      ],
      "metadata": {
        "id": "GHKw2r6yYV7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "7ELMR8kXUh3o"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "cmaGvp-wgLNc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Loading the Data"
      ],
      "metadata": {
        "id": "9oJXlKLYeymq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"complaints_small.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Display the column names\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Display the distribution of complaint types\n",
        "print(\"\\nDistribution of complaint types:\")\n",
        "print(df['Product'].value_counts())"
      ],
      "metadata": {
        "id": "mGga8BmnUcl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297aa3fe-9321-4a54-e9b4-39aa9aa9d2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "                                             Product  \\\n",
            "0  Credit reporting, credit repair services, or o...   \n",
            "1                                       Student loan   \n",
            "2  Credit reporting or other personal consumer re...   \n",
            "3  Credit reporting, credit repair services, or o...   \n",
            "4  Credit reporting or other personal consumer re...   \n",
            "\n",
            "                        Consumer complaint narrative  \n",
            "0  My credit reports are inaccurate. These inaccu...  \n",
            "1  Beginning in XX/XX/XXXX I had taken out studen...  \n",
            "2  I am disputing a charge-off on my account that...  \n",
            "3  I did not consent to, authorize, nor benefit f...  \n",
            "4  I am a federally protected consumer and I am a...  \n",
            "\n",
            "Dataset information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 941128 entries, 0 to 941127\n",
            "Data columns (total 2 columns):\n",
            " #   Column                        Non-Null Count   Dtype \n",
            "---  ------                        --------------   ----- \n",
            " 0   Product                       941128 non-null  object\n",
            " 1   Consumer complaint narrative  941128 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 14.4+ MB\n",
            "None\n",
            "\n",
            "Column names:\n",
            "Index(['Product', 'Consumer complaint narrative'], dtype='object')\n",
            "\n",
            "Distribution of complaint types:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    322966\n",
            "Credit reporting or other personal consumer reports                             252019\n",
            "Debt collection                                                                 117285\n",
            "Mortgage                                                                         49358\n",
            "Checking or savings account                                                      44580\n",
            "Credit card or prepaid card                                                      43575\n",
            "Credit card                                                                      24776\n",
            "Student loan                                                                     18742\n",
            "Money transfer, virtual currency, or money service                               17962\n",
            "Vehicle loan or lease                                                            13777\n",
            "Credit reporting                                                                 12641\n",
            "Payday loan, title loan, or personal loan                                         6940\n",
            "Bank account or service                                                           5920\n",
            "Consumer Loan                                                                     3881\n",
            "Prepaid card                                                                      2402\n",
            "Payday loan, title loan, personal loan, or advance loan                           2300\n",
            "Payday loan                                                                        723\n",
            "Debt or credit management                                                          593\n",
            "Money transfers                                                                    571\n",
            "Other financial service                                                            110\n",
            "Virtual currency                                                                     7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Data Sampling and Class Distribution Analysis\n",
        "\n",
        "Working with large datasets can be computationally intensive during development. Additionally, imbalanced class distribution can affect model performance. In this section, you'll sample the data and analyze class distributions to make informed decisions about your training dataset."
      ],
      "metadata": {
        "id": "L9hr8-FNgpVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "We'll work with a manageable portion of the data to develop and test our approach. While using the complete dataset would likely yield better results, a smaller sample allows us to prototype our solution more efficiently.\n"
      ],
      "metadata": {
        "id": "Cl_g_ZU4h5RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Sample a portion of the dataset (e.g., 10%)\n",
        "sample_fraction = 0.10  # Adjust this fraction as needed\n",
        "sampled_df = df.sample(frac=sample_fraction, random_state=42)\n",
        "\n",
        "# Display the first few rows of the sampled dataset\n",
        "print(\"First 5 rows of the sampled dataset:\")\n",
        "print(sampled_df.head())\n",
        "\n",
        "# Print the shape of the original and sampled datasets\n",
        "print(\"\\nShape of the original dataset:\", df.shape)\n",
        "print(\"Shape of the sampled dataset:\", sampled_df.shape)\n",
        "\n",
        "# Display the distribution of complaint types in the sampled dataset\n",
        "print(\"\\nDistribution of complaint types in the sampled dataset:\")\n",
        "print(sampled_df['Product'].value_counts())"
      ],
      "metadata": {
        "id": "QAJUXNCFhYsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bebe000-a4d6-4622-a34e-b3c6fb0dc0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the sampled dataset:\n",
            "                                                  Product  \\\n",
            "335123  Credit reporting or other personal consumer re...   \n",
            "601718                                           Mortgage   \n",
            "847752  Credit reporting, credit repair services, or o...   \n",
            "765316  Credit reporting or other personal consumer re...   \n",
            "798300  Credit reporting, credit repair services, or o...   \n",
            "\n",
            "                             Consumer complaint narrative  \n",
            "335123  Upon reviewing my credit report, I have identi...  \n",
            "601718  I was doing a rate check to refinance. The age...  \n",
            "847752  This is my 2nd request that I have been a vict...  \n",
            "765316  I'm sending this compliant to inform credit bu...  \n",
            "798300  Im submitting a complaint to you today to info...  \n",
            "\n",
            "Shape of the original dataset: (941128, 2)\n",
            "Shape of the sampled dataset: (94113, 2)\n",
            "\n",
            "Distribution of complaint types in the sampled dataset:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    32262\n",
            "Credit reporting or other personal consumer reports                             25121\n",
            "Debt collection                                                                 11727\n",
            "Mortgage                                                                         4941\n",
            "Checking or savings account                                                      4566\n",
            "Credit card or prepaid card                                                      4269\n",
            "Credit card                                                                      2504\n",
            "Student loan                                                                     1880\n",
            "Money transfer, virtual currency, or money service                               1829\n",
            "Vehicle loan or lease                                                            1439\n",
            "Credit reporting                                                                 1231\n",
            "Payday loan, title loan, or personal loan                                         704\n",
            "Bank account or service                                                           601\n",
            "Consumer Loan                                                                     358\n",
            "Prepaid card                                                                      256\n",
            "Payday loan, title loan, personal loan, or advance loan                           227\n",
            "Debt or credit management                                                          70\n",
            "Payday loan                                                                        69\n",
            "Money transfers                                                                    49\n",
            "Other financial service                                                             8\n",
            "Virtual currency                                                                    2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Let's examine the distribution of ***complaints*** types in our dataset. You'll notice that some products have significantly more instances than others, and some categories are quite similar. For example:\n",
        "\n",
        "- Multiple categories might refer to similar financial products\n",
        "- Some categories might have very few examples\n",
        "- Certain categories might be subcategories of others\n",
        "\n",
        "You have two main approaches to handle this situation:\n",
        "\n",
        "1. **Merging Similar Classes:** Identify categories that represent similar products/services and Combine them to create more robust, general categories\n",
        "\n",
        "2. **Selecting Major Classes:** Only select the categories with sufficient representation\n",
        "\n",
        "\n",
        "\n",
        "> You may choose any approach, but after this step, your data must include **at least five** distinct classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "50a4NJeMiBb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the number of complaints in each product category\n",
        "print(\"Number of complaints per product category:\")\n",
        "print(sampled_df['Product'].value_counts())\n",
        "\n",
        "# Identify under-represented classes (e.g., categories with fewer than 1000 complaints)\n",
        "under_represented = sampled_df['Product'].value_counts()[sampled_df['Product'].value_counts() < 1000]\n",
        "print(\"\\nUnder-represented product categories (fewer than 1000 complaints):\")\n",
        "print(under_represented)\n",
        "\n",
        "# Handle class imbalance by merging similar categories\n",
        "# Example: Merge similar credit reporting categories\n",
        "sampled_df['Product'] = sampled_df['Product'].replace({\n",
        "    'Credit reporting or other personal consumer reports': 'Credit reporting',\n",
        "    'Credit reporting, credit repair services, or other personal consumer reports': 'Credit reporting',\n",
        "    'Credit reporting': 'Credit reporting'\n",
        "})\n",
        "\n",
        "# Example: Merge similar payday loan categories\n",
        "sampled_df['Product'] = sampled_df['Product'].replace({\n",
        "    'Payday loan, title loan, or personal loan': 'Payday loan',\n",
        "    'Payday loan, title loan, personal loan, or advance loan': 'Payday loan',\n",
        "    'Payday loan': 'Payday loan'\n",
        "})\n",
        "\n",
        "# Example: Merge similar credit card categories\n",
        "sampled_df['Product'] = sampled_df['Product'].replace({\n",
        "    'Credit card or prepaid card': 'Credit card',\n",
        "    'Credit card': 'Credit card'\n",
        "})\n",
        "\n",
        "# Drop categories with very few examples (e.g., fewer than 1000 complaints)\n",
        "sampled_df = sampled_df[sampled_df['Product'].map(sampled_df['Product'].value_counts()) >= 1000]\n",
        "\n",
        "# Display the updated distribution of complaint types\n",
        "print(\"\\nUpdated distribution of complaint types after merging and filtering:\")\n",
        "print(sampled_df['Product'].value_counts())\n",
        "\n",
        "# Verify that there are at least five distinct classes\n",
        "assert len(sampled_df['Product'].unique()) >= 5, \"There must be at least five distinct classes.\""
      ],
      "metadata": {
        "id": "nby2Hrwwjd46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce42da57-5065-4ae2-b27f-a018ffb7f3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of complaints per product category:\n",
            "Product\n",
            "Credit reporting, credit repair services, or other personal consumer reports    32262\n",
            "Credit reporting or other personal consumer reports                             25121\n",
            "Debt collection                                                                 11727\n",
            "Mortgage                                                                         4941\n",
            "Checking or savings account                                                      4566\n",
            "Credit card or prepaid card                                                      4269\n",
            "Credit card                                                                      2504\n",
            "Student loan                                                                     1880\n",
            "Money transfer, virtual currency, or money service                               1829\n",
            "Vehicle loan or lease                                                            1439\n",
            "Credit reporting                                                                 1231\n",
            "Payday loan, title loan, or personal loan                                         704\n",
            "Bank account or service                                                           601\n",
            "Consumer Loan                                                                     358\n",
            "Prepaid card                                                                      256\n",
            "Payday loan, title loan, personal loan, or advance loan                           227\n",
            "Debt or credit management                                                          70\n",
            "Payday loan                                                                        69\n",
            "Money transfers                                                                    49\n",
            "Other financial service                                                             8\n",
            "Virtual currency                                                                    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Under-represented product categories (fewer than 1000 complaints):\n",
            "Product\n",
            "Payday loan, title loan, or personal loan                  704\n",
            "Bank account or service                                    601\n",
            "Consumer Loan                                              358\n",
            "Prepaid card                                               256\n",
            "Payday loan, title loan, personal loan, or advance loan    227\n",
            "Debt or credit management                                   70\n",
            "Payday loan                                                 69\n",
            "Money transfers                                             49\n",
            "Other financial service                                      8\n",
            "Virtual currency                                             2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Updated distribution of complaint types after merging and filtering:\n",
            "Product\n",
            "Credit reporting                                      58614\n",
            "Debt collection                                       11727\n",
            "Credit card                                            6773\n",
            "Mortgage                                               4941\n",
            "Checking or savings account                            4566\n",
            "Student loan                                           1880\n",
            "Money transfer, virtual currency, or money service     1829\n",
            "Vehicle loan or lease                                  1439\n",
            "Payday loan                                            1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1.4 Data Encoding and Text Preprocessing\n",
        "\n",
        "Before training our model, we need to prepare both our target labels and text data. This involves converting categorical labels into numerical format and cleaning our text data to improve model performance."
      ],
      "metadata": {
        "id": "lD3oISsijt1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "\n",
        "# Step 1: Label Encoding\n",
        "# Convert product categories into numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "sampled_df['Product_encoded'] = label_encoder.fit_transform(sampled_df['Product'])\n",
        "\n",
        "# Display the mapping of product categories to numerical labels\n",
        "print(\"Product categories and their corresponding numerical labels:\")\n",
        "for i, category in enumerate(label_encoder.classes_):\n",
        "    print(f\"{category}: {i}\")\n",
        "\n",
        "# Step 2: Text Preprocessing\n",
        "# Define a function to clean the text data\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags (if any)\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    return text.strip()\n",
        "\n",
        "# Apply the cleaning function to the 'Consumer complaint narrative' column\n",
        "sampled_df['Cleaned_text'] = sampled_df['Consumer complaint narrative'].apply(clean_text)\n",
        "\n",
        "# Remove very short complaints (e.g., less than 10 words)\n",
        "sampled_df = sampled_df[sampled_df['Cleaned_text'].apply(lambda x: len(x.split()) >= 10)]\n",
        "\n",
        "# Display the first few rows of the cleaned dataset\n",
        "print(\"\\nFirst 5 rows of the cleaned dataset:\")\n",
        "print(sampled_df[['Product', 'Cleaned_text', 'Product_encoded']].head())\n",
        "\n",
        "# Display the shape of the cleaned dataset\n",
        "print(\"\\nShape of the cleaned dataset:\", sampled_df.shape)"
      ],
      "metadata": {
        "id": "pAmaRU92mGyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b95b59-d764-49c1-dac0-fda6f167a54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product categories and their corresponding numerical labels:\n",
            "Checking or savings account: 0\n",
            "Credit card: 1\n",
            "Credit reporting: 2\n",
            "Debt collection: 3\n",
            "Money transfer, virtual currency, or money service: 4\n",
            "Mortgage: 5\n",
            "Payday loan: 6\n",
            "Student loan: 7\n",
            "Vehicle loan or lease: 8\n",
            "\n",
            "First 5 rows of the cleaned dataset:\n",
            "                 Product                                       Cleaned_text  \\\n",
            "335123  Credit reporting  upon reviewing my credit report i have identif...   \n",
            "601718          Mortgage  i was doing a rate check to refinance the agen...   \n",
            "847752  Credit reporting  this is my nd request that i have been a victi...   \n",
            "765316  Credit reporting  im sending this compliant to inform credit bur...   \n",
            "798300  Credit reporting  im submitting a complaint to you today to info...   \n",
            "\n",
            "        Product_encoded  \n",
            "335123                2  \n",
            "601718                5  \n",
            "847752                2  \n",
            "765316                2  \n",
            "798300                2  \n",
            "\n",
            "Shape of the cleaned dataset: (91935, 4)\n"
          ]
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Dataset Creation and Tokenization\n",
        "\n",
        "For training our BERT model, we need to:\n",
        "1. Create a custom Dataset class that will handle tokenization\n",
        "2. Split the data into training and testing sets\n",
        "3. Use BERT's tokenizer to convert text into a format suitable for the model"
      ],
      "metadata": {
        "id": "j4jVvN4oopUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "class ComplaintDataset(Dataset):\n",
        "    \"\"\"A custom Dataset class for handling consumer complaints text data with BERT tokenization.\n",
        "\n",
        "    Parameters:\n",
        "        texts (List[str]): List of complaint texts to be processed\n",
        "        labels (List[int]): List of encoded labels corresponding to each text\n",
        "        tokenizer (BertTokenizer): A BERT tokenizer instance for text processing\n",
        "        max_len (int, optional): Maximum length for padding/truncating texts. Defaults to 512\n",
        "\n",
        "    Returns:\n",
        "        dict: For each item, returns a dictionary containing:\n",
        "            - input_ids (torch.Tensor): Encoded token ids of the text\n",
        "            - attention_mask (torch.Tensor): Attention mask for the padded sequence\n",
        "            - labels (torch.Tensor): Encoded label as a tensor\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,  # Add [CLS] and [SEP] tokens\n",
        "            max_length=self.max_len,  # Truncate/pad to max_len\n",
        "            return_token_type_ids=False,  # Not needed for classification\n",
        "            padding='max_length',  # Pad to max_len\n",
        "            truncation=True,  # Truncate to max_len\n",
        "            return_attention_mask=True,  # Generate attention mask\n",
        "            return_tensors='pt',  # Return PyTorch tensors\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    sampled_df['Cleaned_text'].tolist(),\n",
        "    sampled_df['Product_encoded'].tolist(),\n",
        "    test_size=0.2,  # 80% training, 20% testing\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Create Dataset instances for training and testing\n",
        "train_dataset = ComplaintDataset(train_texts, train_labels, tokenizer)\n",
        "test_dataset = ComplaintDataset(test_texts, test_labels, tokenizer)\n",
        "\n",
        "# Display the size of the training and testing datasets\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Testing dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# Example: Inspect a single item from the training dataset\n",
        "sample_item = train_dataset[0]\n",
        "print(\"\\nSample item from the training dataset:\")\n",
        "print(f\"Input IDs: {sample_item['input_ids']}\")\n",
        "print(f\"Attention Mask: {sample_item['attention_mask']}\")\n",
        "print(f\"Label: {sample_item['labels']}\")"
      ],
      "metadata": {
        "id": "yHLQgJhopEh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ceb42ac096754d8fba2312ddf89a253d",
            "f44fd96b2bf147d9bbbe3ba2de367348",
            "0d171d30693d49afa8b2cbb3378cb534",
            "82a6223a285149abbc209fff6421ed26",
            "5cfd4e782ebf48719be69afb98e1d86a",
            "0b70a1080bc546ae8fb2255272474236",
            "6a27a31a184b405089d92d60679c6ed7",
            "78c1247064e54c96bdfb86183f32e56e",
            "877cf1d66e8846e58076d03f4f495fb1",
            "f64ae9c6888342a791ab25ea31a3b6ee",
            "1262d4a91aee43d89234918a2e8f4522",
            "953d989b9e214940aa824d865f3fb98b",
            "06249cf8dfc349d98cc473e905ce28c3",
            "538522f78251403c879314c6357cabfe",
            "4e1940199bd04361b73b3ea370576513",
            "9c981791b30e428180f0f44a3ebfd5fc",
            "c7a4e2626b844ea7ba6a4d42adef9abb",
            "512766aeb9ee443f9907539c75bae562",
            "226dd29a783244d586f01932d1415384",
            "d712e43ace9b4ec4a5cb419ab30e160e",
            "4f8ed5b6ec724112b6d740cb65c11600",
            "a79b7fc75f3a4c47a78f852954e22d45",
            "98025bfad14049eebdebe18d4f9f80f9",
            "c1d4bd85dbac474c82588b894f2ea68e",
            "63cb115e204441b9bf4338c5afeb6551",
            "3739b2bf65214b76bd67d20c39667f94",
            "55910a9c432d4c50a55d68ddcdfbf7e5",
            "f205810405a14461b54f06e6ccd761b0",
            "3d9c7578ffd24da7a5b3d53f1dd42e1e",
            "014cf75abb31433ea7e0aabcfe399d5b",
            "56c65795b1b346ce845ee36346709129",
            "c22b43dd082841588ee09d0ef713c33b",
            "d775969c4d39476687e1fc0a51931aab",
            "bdb212e89e8c40d686c44d98924ef2e4",
            "fae1b191304545c188d903f2137280b2",
            "5bb7024eef44406db60b5ff205b3b460",
            "dd2e4ff3acbb43488cc72ad5c7973b55",
            "dd7ddbcd74de41b2aa7f3e28b8552c40",
            "1ea28e5c77464fe18d348e30e0e6f410",
            "e96b05bdcdec4bdfbdcb23b8cb1145aa",
            "5de84e73b7f74d7e97e16564d7564d6c",
            "d600ca7f1c974aa98d5e8b5da7f5c7ba",
            "1f7c1a124f4d419c95c68bdd4fcf8214",
            "07394e00ffd944e09e4616cc80f8fd9e"
          ]
        },
        "outputId": "e4fe36e5-524e-41f7-a4c5-69afc29e9557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceb42ac096754d8fba2312ddf89a253d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "953d989b9e214940aa824d865f3fb98b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98025bfad14049eebdebe18d4f9f80f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdb212e89e8c40d686c44d98924ef2e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 73548\n",
            "Testing dataset size: 18387\n",
            "\n",
            "Sample item from the training dataset:\n",
            "Input IDs: tensor([  101,  1045,  2031,  2025,  2018,  2019,  4070,  2007,  2023,  2194,\n",
            "         1998,  2038,  6303, 27354,  1997,  7016,  3807,  2085,  1045,  2106,\n",
            "         2025,  4607,  2046,  2151,  3206,  2007,  2023,  2194,  1998,  2038,\n",
            "         2025,  2363,  2151, 12653,  2012,  2035,  2013,  2068,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Label: 3\n"
          ]
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Training a Small-Size BERT Model\n",
        "\n",
        "In this part, we will explore how to build and train a small-sized BERT model for our classification task. Instead of using the full-sized BERT model, which is computationally expensive, we will create a smaller version using the Transformers library."
      ],
      "metadata": {
        "id": "aMcc2gsbt0iJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "import torch\n",
        "\n",
        "# Step 1: Define the BERT model for sequence classification\n",
        "# Set up the configuration for a smaller BERT model\n",
        "config = BertConfig(\n",
        "    vocab_size=30522,  # Vocabulary size of BERT\n",
        "    hidden_size=128,  # Smaller hidden size (default is 768)\n",
        "    num_hidden_layers=4,  # Fewer layers (default is 12)\n",
        "    num_attention_heads=4,  # Fewer attention heads (default is 12)\n",
        "    intermediate_size=512,  # Smaller intermediate size (default is 3072)\n",
        "    num_labels=len(label_encoder.classes_),  # Number of output labels\n",
        "    max_position_embeddings=512,  # Maximum sequence length\n",
        ")\n",
        "\n",
        "# Initialize the BERT model with the custom configuration\n",
        "model = BertForSequenceClassification(config)\n",
        "\n",
        "# Move the model to the appropriate device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Step 2: Print the total number of trainable parameters in the model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total number of trainable parameters in the model: {total_params:,}\")"
      ],
      "metadata": {
        "id": "3RS5oBz3qmvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2866a83-496d-4cdc-e619-a63d1c8a3def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters in the model: 4,783,625\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Now that you have defined your model, it's time to train it!☠️\n",
        "\n",
        "Training a model of this size can take some time, depending on the available resources. To manage this, you can train your model for just **2–3 epochs** to demonstrate progress. Here are some hints:\n",
        "- **Training Metrics:** Ensure you print enough metrics, such as loss and accuracy, to track the training progress.\n",
        "- **Interactive Monitoring:** Use the `tqdm` library to display the progress of your training loop in real-time."
      ],
      "metadata": {
        "id": "Xr4Z14a6wL2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Define the optimizer and number of epochs\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)  # Learning rate for BERT fine-tuning\n",
        "num_epochs = 3  # Number of training epochs\n",
        "\n",
        "# Create DataLoader for training and testing datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Use tqdm for real-time progress monitoring\n",
        "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move batch data to the appropriate device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        # Compute loss\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    # Compute average loss and accuracy for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    print(f\"Training Loss: {avg_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Step 2: Evaluate the model on the test dataset\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        test_correct += (predictions == labels).sum().item()\n",
        "        test_samples += labels.size(0)\n",
        "\n",
        "# Compute test accuracy\n",
        "test_accuracy = test_correct / test_samples\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "FRZW-F9Dw6AI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6aa07b1-3846-46ee-bbf7-d923d731e383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4597/4597 [08:30<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0516, Training Accuracy: 0.6723\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4597/4597 [08:25<00:00,  9.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.7515, Training Accuracy: 0.7401\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4597/4597 [08:20<00:00,  9.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.6533, Training Accuracy: 0.7868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1150/1150 [01:37<00:00, 11.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Fine-Tuning TinyBERT with LoRA\n",
        "\n",
        "As you have experienced, training even a small-sized BERT model can be computationally intensive and time-consuming. To address these challenges, we explore **Parameter-Efficient Fine-Tuning (PEFT)** methods, which allow us to utilize the power of large pretrained models without requiring extensive resources.\n",
        "\n",
        "---\n",
        "\n",
        "### **Parameter-Efficient Fine-Tuning (PEFT)**\n",
        "\n",
        "PEFT methods focus on fine-tuning only a small portion of the model’s parameters while keeping most of the pretrained weights frozen. This drastically reduces the computational and storage requirements while leveraging the rich knowledge embedded in pretrained models.\n",
        "\n",
        "One popular PEFT method is LoRA (Low-Rank Adaptation).\n",
        "\n",
        "- **What is LoRA?**\n",
        "\n",
        "LoRA introduces a mechanism to fine-tune large language models by injecting small low-rank matrices into the model's architecture. Instead of updating all parameters during training, LoRA trains these small matrices while keeping the majority of the original parameters frozen.  This is achieved as follows:\n",
        "\n",
        "1. **Frozen Weights**: The pretrained weights of the model, represented as a weight matrix $ W \\in \\mathbb{R}^{d \\times k} $, remain **frozen** during fine-tuning.\n",
        "\n",
        "2. **Low-Rank Decomposition**:\n",
        "   Instead of directly updating $ W $, LoRA introduces two trainable matrices, $ A \\in \\mathbb{R}^{d \\times r} $ and $ B \\in \\mathbb{R}^{r \\times k} $, where $ r \\ll \\min(d, k) $.  \n",
        "   These matrices approximate the update to $ W $ as:\n",
        "   $$\n",
        "   \\Delta W = A \\cdot B\n",
        "   $$\n",
        "\n",
        "   Here, $ r $, the rank of the decomposition, is a key hyperparameter that determines the trade-off between computational cost and model capacity.\n",
        "\n",
        "3. **Adaptation**:\n",
        "   During training, instead of updating $ W $, the adapted weight is:\n",
        "   $$\n",
        "   W' = W + \\Delta W = W + A \\cdot B\n",
        "   $$\n",
        "   Only the low-rank matrices $ A $ and $ B $ are optimized, while $ W $ remains fixed.\n",
        "\n",
        "4. **Efficiency**:\n",
        "   Since $ r $ is much smaller than $ d $ and $ k $, the number of trainable parameters in $ A $ and $ B $ is significantly less than in $ W $. This makes the approach highly efficient both in terms of computation and memory.\n",
        "\n",
        "---\n",
        "\n",
        "###  **Fine-Tuning TinyBERT**\n",
        "\n",
        "For this part, we will fine-tune **TinyBERT**, a distilled version of BERT, using the LoRA method.\n",
        "\n",
        "- **What is TinyBERT?**\n",
        "\n",
        "TinyBERT is a lightweight version of the original BERT model created through knowledge distillation. It significantly reduces the model size and inference latency while preserving much of the original BERT’s effectiveness. Here are some key characteristics of TinyBERT:\n",
        "- It is designed to be more resource-efficient for tasks such as classification, question answering, and more.\n",
        "- TinyBERT retains a compact structure with fewer layers and parameters, making it ideal for fine-tuning with limited computational resources.\n"
      ],
      "metadata": {
        "id": "-yHtTYcpz6AW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Similar to the previous section, training this model might take some time. Given the resource limitations, you can train the model for just **2-3 epochs** to demonstrate the process.\n"
      ],
      "metadata": {
        "id": "n_Og-pBeV5x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "fe1vGCZwU7MZ"
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load the pre-trained TinyBERT model and tokenizer\n",
        "model_name = \"prajjwal1/bert-tiny\"\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Define LoRA Configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=8,  # Rank of the low-rank matrices\n",
        "    lora_alpha=16,  # Scaling factor for the low-rank matrices\n",
        "    target_modules=[\"query\", \"value\"],  # Modules to apply LoRA (e.g., attention layers)\n",
        "    lora_dropout=0.1,  # Dropout rate for LoRA layers\n",
        "    bias=\"none\",  # Whether to add bias terms\n",
        ")\n",
        "\n",
        "# Step 3: Apply LoRA to the model\n",
        "lora_model = get_peft_model(base_model, lora_config)\n",
        "\n",
        "# Display the number of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(lora_model)\n",
        "print(f\"Total number of trainable parameters in the LoRA model: {total_params:,}\")\n",
        "\n",
        "# Step 4: Training configuration\n",
        "optimizer = AdamW(lora_model.parameters(), lr=2e-5)  # Learning rate for fine-tuning\n",
        "criterion = CrossEntropyLoss()  # Loss function for classification\n",
        "\n",
        "# Step 5: Training loop\n",
        "num_epochs = 3  # Number of training epochs\n",
        "\n",
        "# Move the model to the GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "lora_model = lora_model.to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    lora_model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Use tqdm for real-time progress monitoring\n",
        "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move batch data to the GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = lora_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        # Compute loss\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        total_correct += (predictions == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    # Compute average loss and accuracy for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    print(f\"Training Loss: {avg_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Step 6: Evaluate the model on the test dataset\n",
        "lora_model.eval()\n",
        "test_correct = 0\n",
        "test_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        # Move batch data to the GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = lora_model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        test_correct += (predictions == labels).sum().item()\n",
        "        test_samples += labels.size(0)\n",
        "\n",
        "# Compute test accuracy\n",
        "test_accuracy = test_correct / test_samples\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "J395FrcWMbmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c952fe-6048-46e0-fa6d-a03fbdff7d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters in the LoRA model: 8,192\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 4597/4597 [07:21<00:00, 10.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.7871, Training Accuracy: 0.6002\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  80%|███████▉  | 3658/4597 [05:43<02:08,  7.32it/s]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to saving issues, the complete segment doesn't show in the output cell. Below is the correct output cell gotten from the RAW format:\n",
        "\n",
        "```\n",
        "Execution output\n",
        "1KB\n",
        "\tStream\n",
        "\t\tSome weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
        "\t\tYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
        "\t\tTotal number of trainable parameters in the LoRA model: 8,192\n",
        "\t\tEpoch 1/3\n",
        "\t\tTraining: 100%|██████████| 4597/4597 [07:21<00:00, 10.41it/s]\n",
        "\t\tTraining Loss: 1.7871, Training Accuracy: 0.6002\n",
        "\t\tEpoch 2/3\n",
        "\t\tTraining: 100%|██████████| 4597/4597 [07:14<00:00, 10.58it/s]\n",
        "\t\tTraining Loss: 1.7152, Training Accuracy: 0.6311\n",
        "\t\tEpoch 3/3\n",
        "\t\tTraining: 100%|██████████| 4597/4597 [07:16<00:00, 10.54it/s]\n",
        "\t\tTraining Loss: 1.7097, Training Accuracy: 0.6311\n",
        "\t\tTesting: 100%|██████████| 1150/1150 [01:24<00:00, 13.57it/s]\n",
        "\t\tTest Accuracy: 0.6293\n",
        "  ```"
      ],
      "metadata": {
        "id": "6Py1V3Ar4P6b"
      }
    }
  ]
}